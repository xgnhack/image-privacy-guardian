"""
ç›‘æ§ç®¡ç†å™¨ - Aegis Folder Watch
è´Ÿè´£æ–‡ä»¶å¤¹ç›‘æ§ã€æ–‡ä»¶å¤„ç†å’Œå¤±è´¥å¤„ç†çš„åç«¯å¼•æ“
"""

import os
import time
import hashlib
import json
import shutil
import threading
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

from PyQt5.QtCore import QObject, pyqtSignal, QTimer
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

from sanitizer_engine import ImageSanitizer


class ImageFileHandler(FileSystemEventHandler):
    """å›¾åƒæ–‡ä»¶äº‹ä»¶å¤„ç†å™¨"""
    
    def __init__(self, monitoring_manager):
        super().__init__()
        self.monitoring_manager = monitoring_manager
        self.processing_delay = 1.0  # æ–‡ä»¶ç¨³å®šç­‰å¾…æ—¶é—´
        self.processed_in_session = set()  # æœ¬æ¬¡ä¼šè¯å·²å¤„ç†çš„æ–‡ä»¶
    
    def on_created(self, event):
        """æ–‡ä»¶åˆ›å»ºäº‹ä»¶"""
        if not event.is_directory:
            self.handle_file_event(event.src_path, "åˆ›å»º")
    
    def on_modified(self, event):
        """æ–‡ä»¶ä¿®æ”¹äº‹ä»¶"""
        if not event.is_directory:
            # é¿å…å¤„ç†æˆ‘ä»¬è‡ªå·±åˆ›å»ºçš„ä¸´æ—¶æ–‡ä»¶
            if ".aegis_temp" in event.src_path or "_cleaned" in event.src_path:
                return
            self.handle_file_event(event.src_path, "ä¿®æ”¹")
    
    def handle_file_event(self, file_path, event_type):
        """å¤„ç†æ–‡ä»¶äº‹ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            if not self.monitoring_manager.is_image_file(file_path):
                return
            
            # é¿å…å¤„ç†å¤‡ä»½æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
            if self.monitoring_manager.backup_folder in file_path:
                return
            
            # é¿å…å¤„ç†ä¸´æ—¶æ–‡ä»¶å’Œå·²æ¸…ç†çš„æ–‡ä»¶
            file_name = os.path.basename(file_path)
            if ('_cleaned' in file_name or '_FAILED_' in file_name or 
                '_ERROR_' in file_name or file_name.startswith('~')):
                return
            
            # è¿‡æ»¤æ‰å¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶ï¼ˆé˜²æ­¢å¤„ç†å·²ç»å¤‡ä»½çš„æ–‡ä»¶ï¼‰
            if '_20' in file_name and ('_FAILED_' in file_name or len(file_name.split('_')) > 3):
                return
            
            # é¿å…é‡å¤å¤„ç†åŒä¸€æ–‡ä»¶
            if file_path in self.processed_in_session:
                return
            
            # ç­‰å¾…æ–‡ä»¶ç¨³å®š
            self.wait_for_file_ready(file_path)
            
            # å†æ¬¡æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                return
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡
            if self.monitoring_manager.is_file_processed(file_path):
                return
            
            # æ ‡è®°ä¸ºæœ¬æ¬¡ä¼šè¯å·²å¤„ç†
            self.processed_in_session.add(file_path)
            
            # æäº¤å¤„ç†ä»»åŠ¡
            self.monitoring_manager.submit_processing_task(file_path, event_type)
            
        except Exception as e:
            self.monitoring_manager.log_message.emit(
                f"âŒ å¤„ç†æ–‡ä»¶äº‹ä»¶å¤±è´¥: {file_path} - {str(e)}"
            )
    
    def wait_for_file_ready(self, file_path, max_wait=10):
        """ç­‰å¾…æ–‡ä»¶å‡†å¤‡å°±ç»ª"""
        start_time = time.time()
        last_size = -1
        
        while time.time() - start_time < max_wait:
            try:
                if not os.path.exists(file_path):
                    time.sleep(0.1)
                    continue
                
                current_size = os.path.getsize(file_path)
                if current_size == last_size and current_size > 0:
                    # æ–‡ä»¶å¤§å°ç¨³å®šï¼Œå°è¯•æ‰“å¼€æ–‡ä»¶
                    try:
                        with open(file_path, 'rb') as f:
                            f.read(1)
                        break  # æ–‡ä»¶å¯ä»¥æ­£å¸¸è®¿é—®
                    except:
                        pass  # æ–‡ä»¶ä»åœ¨å†™å…¥ä¸­
                
                last_size = current_size
                time.sleep(self.processing_delay)
                
            except Exception:
                time.sleep(0.1)


class ProcessingWorker:
    """å¤„ç†å·¥ä½œå™¨ - åœ¨å•ç‹¬çº¿ç¨‹ä¸­å¤„ç†å•ä¸ªæ–‡ä»¶"""
    
    def __init__(self, file_path: str, event_type: str, monitoring_manager):
        self.file_path = file_path
        self.event_type = event_type
        self.monitoring_manager = monitoring_manager
        self.sanitizer = ImageSanitizer()
        
    def process_file(self):
        """å¤„ç†æ–‡ä»¶"""
        try:
            # é¦–å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.file_path):
                return  # é™é»˜è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
            if self.monitoring_manager.is_file_processed(self.file_path):
                return  # é™é»˜è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶
            
            # å†æ¬¡æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆé˜²æ­¢åœ¨æ£€æŸ¥è¿‡ç¨‹ä¸­è¢«åˆ é™¤ï¼‰
            if not os.path.exists(self.file_path):
                return  # é™é»˜è·³è¿‡
            
            # å¤‡ä»½åŸæ–‡ä»¶
            backup_path = self.create_backup_path()
            
            # è®°å½•å¼€å§‹å¤„ç†
            self.monitoring_manager.log_message.emit(
                f"ğŸ”„ å¼€å§‹å¤„ç† ({self.event_type}): {os.path.basename(self.file_path)}"
            )
            
            # æ‰§è¡Œæ¸…ç†ï¼ˆç›´æ¥æ›¿æ¢åŸæ–‡ä»¶ï¼‰
            success = self.sanitizer.clean_image(self.file_path, None, self.monitoring_manager.advanced_config)
            
            if success:
                # æˆåŠŸå¤„ç†
                # æ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†
                self.monitoring_manager.mark_file_processed(self.file_path)
                
                # åˆ é™¤å¤‡ä»½
                if os.path.exists(backup_path):
                    os.remove(backup_path)
                    
                # è®¡ç®—å¤„ç†åæ–‡ä»¶çš„å“ˆå¸Œå€¼
                file_hash = self.monitoring_manager.calculate_file_hash(self.file_path)
                hash_display = file_hash[:8] + "..." if file_hash else "æœªçŸ¥"
                
                self.monitoring_manager.log_message.emit(
                    f"âœ… å¤„ç†æˆåŠŸ: {os.path.basename(self.file_path)}"
                )
                
                # æ›´æ–°ç»Ÿè®¡
                self.monitoring_manager.increment_success()
                    
            else:
                # å¤„ç†å¤±è´¥ï¼Œæ¢å¤å¤‡ä»½
                if os.path.exists(backup_path):
                    shutil.move(backup_path, self.file_path)
                raise Exception("å›¾åƒæ¸…ç†è¿‡ç¨‹å¤±è´¥")
                
        except FileNotFoundError:
            # æ–‡ä»¶ä¸å­˜åœ¨é”™è¯¯ï¼Œé™é»˜å¤„ç†
            return
        except Exception as e:
            # åªæœ‰çœŸæ­£çš„å¤„ç†é”™è¯¯æ‰è®°å½•
            if "ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„æ–‡ä»¶" not in str(e):
                self.handle_failure(str(e))
            
    def create_output_path(self):
        """åˆ›å»ºè¾“å‡ºè·¯å¾„"""
        file_dir = os.path.dirname(self.file_path)
        file_name = os.path.basename(self.file_path)
        name, ext = os.path.splitext(file_name)
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
        output_path = os.path.join(file_dir, f"{name}_cleaned{ext}")
        return output_path
        
    def create_backup_path(self):
        """åˆ›å»ºå¤‡ä»½è·¯å¾„"""
        # æ£€æŸ¥åŸæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.file_path):
            raise FileNotFoundError(f"åŸæ–‡ä»¶ä¸å­˜åœ¨: {self.file_path}")
        
        # ä½¿ç”¨ç»Ÿä¸€çš„å¤‡ä»½è·¯å¾„åˆ›å»ºæ–¹æ³•
        backup_path = self.create_dated_backup_path(backup_type="processing")
        
        # å¤åˆ¶åŸæ–‡ä»¶åˆ°å¤‡ä»½ä½ç½®
        try:
            # åªæœ‰åœ¨éœ€è¦å¤åˆ¶æ–‡ä»¶æ—¶æ‰åˆ›å»ºç›®å½•
            os.makedirs(os.path.dirname(backup_path), exist_ok=True)
            shutil.copy2(self.file_path, backup_path)
        except Exception as e:
            raise Exception(f"åˆ›å»ºå¤‡ä»½å¤±è´¥: {str(e)}")
        
        return backup_path
        
    def handle_failure(self, error_message):
        """å¤„ç†å¤±è´¥æƒ…å†µ - å¤±è´¥æ–‡ä»¶ä¿ç•™åœ¨ç›‘æ§æ–‡ä»¶å¤¹ä¸­ï¼ŒåŒæ—¶å¤åˆ¶åˆ°å¤‡ä»½æ–‡ä»¶å¤¹"""
        try:
            if os.path.exists(self.file_path):
                # åˆ›å»ºæŒ‰æ—¥æœŸåˆ†ç±»çš„å¤‡ä»½ç›®å½•ç»“æ„
                backup_path = self.create_dated_backup_path()
                
                # åªæœ‰åœ¨éœ€è¦å¤‡ä»½æ–‡ä»¶æ—¶æ‰åˆ›å»ºç›®å½•
                try:
                    # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
                    os.makedirs(os.path.dirname(backup_path), exist_ok=True)
                    
                    # å¤åˆ¶å¤±è´¥æ–‡ä»¶åˆ°å¤‡ä»½ç›®å½•ï¼ˆä¿ç•™åŸæ–‡ä»¶åœ¨ç›‘æ§æ–‡ä»¶å¤¹ä¸­ï¼‰
                    shutil.copy2(self.file_path, backup_path)
                    
                    # åˆ›å»ºé”™è¯¯æ—¥å¿—ï¼ˆæ”¾åœ¨åŒä¸€ç›®å½•ï¼‰
                    file_name = os.path.basename(self.file_path)
                    name, ext = os.path.splitext(file_name)
                    error_log_path = os.path.join(os.path.dirname(backup_path), f"{name}_error_log.txt")
                    with open(error_log_path, 'w', encoding='utf-8') as f:
                        f.write(f"åŸå§‹æ–‡ä»¶: {self.file_path}\n")
                        f.write(f"äº‹ä»¶ç±»å‹: {self.event_type}\n")
                        f.write(f"å¤±è´¥æ—¶é—´: {datetime.now().isoformat()}\n")
                        f.write(f"é”™è¯¯ä¿¡æ¯: {error_message}\n")
                        f.write(f"å¤„ç†é…ç½®: {self.monitoring_manager.advanced_config}\n")
                        
                    self.monitoring_manager.log_message.emit(
                        f"âŒ å¤„ç†å¤±è´¥: {os.path.basename(self.file_path)} - {error_message}"
                    )
                    self.monitoring_manager.log_message.emit(
                        f"ğŸ“ å¤±è´¥æ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_path}ï¼ˆåŸæ–‡ä»¶ä¿ç•™åœ¨ç›‘æ§æ–‡ä»¶å¤¹ä¸­ï¼‰"
                    )
                    
                except Exception as backup_error:
                    # å¦‚æœå¤‡ä»½å¤±è´¥ï¼Œåªè®°å½•é”™è¯¯ï¼Œä¸åˆ›å»ºç©ºç›®å½•
                    self.monitoring_manager.log_message.emit(
                        f"âŒ å¤„ç†å¤±è´¥: {os.path.basename(self.file_path)} - {error_message}"
                    )
                    self.monitoring_manager.log_message.emit(
                        f"ğŸ’¥ å¤‡ä»½å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: {str(backup_error)}"
                    )
            else:
                # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåªè®°å½•é”™è¯¯ï¼Œä¸åˆ›å»ºä»»ä½•ç›®å½•
                self.monitoring_manager.log_message.emit(
                    f"âš ï¸ å¤„ç†å¤±è´¥ä½†æ–‡ä»¶å·²ä¸å­˜åœ¨: {os.path.basename(self.file_path)} - {error_message}"
                )
            
        except Exception as general_error:
            self.monitoring_manager.log_message.emit(
                f"ğŸ’¥ å¤„ç†å¤±è´¥æƒ…å†µæ—¶å‡ºé”™: {str(general_error)}"
            )
            
        finally:
            # æ›´æ–°ç»Ÿè®¡
            self.monitoring_manager.increment_failure()
    
    def create_dated_backup_path(self, backup_type="failed"):
        """åˆ›å»ºæŒ‰æ—¥æœŸåˆ†ç±»çš„å¤‡ä»½è·¯å¾„ï¼Œä¿æŒåŸæœ‰ç›®å½•ç»“æ„
        
        Args:
            backup_type: å¤‡ä»½ç±»å‹ï¼Œå¯ä»¥æ˜¯ "failed"ï¼ˆå¤±è´¥ï¼‰æˆ– "processing"ï¼ˆå¤„ç†ä¸­ï¼‰
        """
        try:
            # è·å–å½“å‰æ—¶é—´æˆ³ï¼ˆç²¾ç¡®åˆ°åˆ†é’Ÿï¼‰
            timestamp = datetime.now().strftime("%Y%m%d%H%M")
            
            # è®¡ç®—ç›¸å¯¹äºç›‘æ§æ–‡ä»¶å¤¹çš„è·¯å¾„
            relative_path = None
            monitored_folder_name = "unknown_source"
            
            for monitored_folder in self.monitoring_manager.monitored_folders:
                if self.file_path.startswith(monitored_folder):
                    # è·å–ç›¸å¯¹è·¯å¾„
                    relative_path = os.path.relpath(self.file_path, monitored_folder)
                    # è·å–ç›‘æ§æ–‡ä»¶å¤¹çš„åç§°ä½œä¸ºæ ¹ç›®å½•
                    monitored_folder_name = os.path.basename(monitored_folder.rstrip(os.sep))
                    break
            
            if relative_path is None:
                # å¦‚æœæ— æ³•ç¡®å®šç›¸å¯¹è·¯å¾„ï¼Œä½¿ç”¨æ–‡ä»¶å
                relative_path = os.path.basename(self.file_path)
            
            # æ„å»ºå¤‡ä»½è·¯å¾„ï¼šé…ç½®çš„å¤‡ä»½æ–‡ä»¶å¤¹/æ—¥æœŸæ—¶é—´/ç›‘æ§æ–‡ä»¶å¤¹å/ç›¸å¯¹è·¯å¾„
            backup_base = os.path.join(self.monitoring_manager.backup_folder, timestamp, monitored_folder_name)
            backup_path = os.path.join(backup_base, relative_path)
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ åºå·
            if os.path.exists(backup_path):
                name, ext = os.path.splitext(backup_path)
                counter = 1
                while os.path.exists(f"{name}_{counter:03d}{ext}"):
                    counter += 1
                backup_path = f"{name}_{counter:03d}{ext}"
            
            return backup_path
            
        except Exception as e:
            # å¦‚æœåˆ›å»ºè·¯å¾„å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„å¤‡ä»½è·¯å¾„
            timestamp = datetime.now().strftime("%Y%m%d%H%M")
            file_name = os.path.basename(self.file_path)
            return os.path.join(self.monitoring_manager.backup_folder, timestamp, "fallback", file_name)


class MonitoringManager(QObject):
    """ç›‘æ§ç®¡ç†å™¨ - åç«¯å¼•æ“"""
    
    # ä¿¡å·å®šä¹‰
    log_message = pyqtSignal(str)
    stats_updated = pyqtSignal(dict)
    error_occurred = pyqtSignal(str)
    
    def __init__(self, backup_folder=None):
        super().__init__()
        
        # ç›‘æ§çŠ¶æ€
        self.is_running = False
        self.observers = []
        
        # é…ç½®
        self.config = {}
        self.advanced_config = {}  # æ·»åŠ é»˜è®¤çš„advanced_config
        self.monitored_folders = []
        
        # å¤‡ä»½æ–‡ä»¶å¤¹é…ç½®
        self.backup_folder = self.load_backup_config(backup_folder)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'folders': 0,
            'processed': 0,
            'success': 0,
            'failed': 0
        }
        self.stats_lock = Lock()
        
        # å¤„ç†çº¿ç¨‹æ± 
        self.processing_threads = []
        self.max_concurrent_threads = 3
        
        # å·²å¤„ç†æ–‡ä»¶çš„å“ˆå¸Œè®°å½•
        self.processed_files = {}  # {file_path: {'hash': hash_value, 'timestamp': timestamp}}
        self.processed_files_lock = Lock()
        self.log_file_path = "aegis_processed_files.json"
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        self.supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp', '.heif', '.heic'}
        
        # åŠ è½½å·²å¤„ç†æ–‡ä»¶è®°å½•
        self.load_processed_files()
        
        # ç»Ÿè®¡æ›´æ–°å®šæ—¶å™¨
        self.stats_timer = QTimer()
        self.stats_timer.timeout.connect(self.emit_stats)
        self.stats_timer.start(1000)  # æ¯ç§’æ›´æ–°ä¸€æ¬¡ç»Ÿè®¡
    
    def load_backup_config(self, backup_folder=None):
        """åŠ è½½å¤‡ä»½é…ç½®"""
        if backup_folder:
            return backup_folder
            
        try:
            # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½
            config_path = os.path.join("aegis_config", "backup_config.json")
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    backup_config = json.load(f)
                    configured_folder = backup_config.get('backup_folder', 'errorbak')
                    
                    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
                    if not os.path.isabs(configured_folder):
                        app_root = os.path.dirname(os.path.abspath(__file__))
                        return os.path.join(app_root, configured_folder)
                    else:
                        return configured_folder
        except Exception as e:
            print(f"åŠ è½½å¤‡ä»½é…ç½®å¤±è´¥: {e}")
        
        # é»˜è®¤å¤‡ä»½æ–‡ä»¶å¤¹
        app_root = os.path.dirname(os.path.abspath(__file__))
        return os.path.join(app_root, "errorbak")
        
    def start_monitoring(self, folders: List[str], config: dict):
        """å¼€å§‹ç›‘æ§"""
        try:
            self.monitored_folders = folders.copy()
            self.config = config.copy()
            self.advanced_config = config.copy()  # æ·»åŠ advanced_configå±æ€§
            self.is_running = True
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats['folders'] = len(folders)
            
            # é¦–æ¬¡æ‰«ææ‰€æœ‰æ–‡ä»¶å¤¹ä¸­çš„å›¾åƒæ–‡ä»¶
            self.log_message.emit("ğŸ” å¼€å§‹é¦–æ¬¡æ‰«æç°æœ‰æ–‡ä»¶...")
            self.initial_scan(folders)
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶å¤¹åˆ›å»ºè§‚å¯Ÿè€…
            for folder in folders:
                if os.path.exists(folder):
                    observer = Observer()
                    event_handler = ImageFileHandler(self)
                    observer.schedule(event_handler, folder, recursive=True)
                    observer.start()
                    self.observers.append(observer)
                    
                    self.log_message.emit(f"ğŸ‘ï¸ å¼€å§‹ç›‘æ§æ–‡ä»¶å¤¹: {folder}")
                else:
                    self.log_message.emit(f"âš ï¸ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder}")
                    
            self.log_message.emit(f"ğŸš€ ç›‘æ§ç®¡ç†å™¨å·²å¯åŠ¨ï¼Œç›‘æ§ {len(self.observers)} ä¸ªæ–‡ä»¶å¤¹")
            
        except Exception as e:
            self.error_occurred.emit(f"å¯åŠ¨ç›‘æ§å¤±è´¥: {str(e)}")
            
    def initial_scan(self, folders):
        """é¦–æ¬¡æ‰«ææ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒæ–‡ä»¶"""
        for folder in folders:
            if not os.path.exists(folder):
                continue
                
            try:
                for root, dirs, files in os.walk(folder):
                    for file in files:
                        file_path = os.path.join(root, file)
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾åƒæ–‡ä»¶
                        if self.is_image_file(file_path):
                            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
                            if not self.is_file_processed(file_path):
                                self.log_message.emit(f"ğŸ“ å‘ç°æ–°æ–‡ä»¶: {os.path.basename(file_path)}")
                                self.submit_processing_task(file_path, "é¦–æ¬¡æ‰«æ")
                            
            except Exception as e:
                self.log_message.emit(f"âŒ æ‰«ææ–‡ä»¶å¤¹å¤±è´¥ {folder}: {str(e)}")
            
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        try:
            self.is_running = False
            
            # åœæ­¢æ‰€æœ‰è§‚å¯Ÿè€…
            for observer in self.observers:
                observer.stop()
                observer.join()
                
            self.observers.clear()
            
            # ç­‰å¾…å¤„ç†çº¿ç¨‹å®Œæˆ
            self.wait_for_processing_threads()
            
            self.log_message.emit("â¹ï¸ ç›‘æ§ç®¡ç†å™¨å·²åœæ­¢")
            
        except Exception as e:
            self.error_occurred.emit(f"åœæ­¢ç›‘æ§å¤±è´¥: {str(e)}")
            
    def queue_file_for_processing(self, file_path: str, event_type: str):
        """å°†æ–‡ä»¶åŠ å…¥å¤„ç†é˜Ÿåˆ—"""
        if not self.is_running:
            return
            
        try:
            # æ¸…ç†å·²å®Œæˆçš„çº¿ç¨‹
            self.cleanup_finished_threads()
            
            # æ£€æŸ¥å¹¶å‘é™åˆ¶
            if len(self.processing_threads) >= self.max_concurrent_threads:
                self.log_message.emit(f"â³ å¤„ç†é˜Ÿåˆ—å·²æ»¡ï¼Œç­‰å¾…å¤„ç†: {os.path.basename(file_path)}")
                return
                
            # åˆ›å»ºå¤„ç†å·¥ä½œå™¨
            worker = ProcessingWorker(file_path, event_type, self)
            
            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œ
            thread = threading.Thread(target=worker.process_file, daemon=True)
            thread.start()
            
            self.processing_threads.append(thread)
            self.increment_processed()
            
        except Exception as e:
            self.log_message.emit(f"âŒ æäº¤å¤„ç†ä»»åŠ¡å¤±è´¥: {str(e)}")
    
    def submit_processing_task(self, file_path: str, event_type: str):
        """æäº¤å¤„ç†ä»»åŠ¡ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        self.queue_file_for_processing(file_path, event_type)
            
    def cleanup_finished_threads(self):
        """æ¸…ç†å·²å®Œæˆçš„çº¿ç¨‹"""
        self.processing_threads = [t for t in self.processing_threads if t.is_alive()]
        
    def wait_for_processing_threads(self, timeout=30):
        """ç­‰å¾…å¤„ç†çº¿ç¨‹å®Œæˆ"""
        start_time = time.time()
        
        while self.processing_threads and (time.time() - start_time) < timeout:
            self.cleanup_finished_threads()
            time.sleep(0.5)
            
        # å¼ºåˆ¶ç»“æŸå‰©ä½™çº¿ç¨‹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if self.processing_threads:
            self.log_message.emit(f"âš ï¸ {len(self.processing_threads)} ä¸ªå¤„ç†çº¿ç¨‹æœªèƒ½åŠæ—¶å®Œæˆ")
            
    def update_config(self, new_config: dict):
        """æ›´æ–°é…ç½®"""
        self.config = new_config.copy()
        self.advanced_config = new_config.copy()  # åŒæ—¶æ›´æ–°advanced_config
        self.log_message.emit("âš™ï¸ é…ç½®å·²æ›´æ–°")
        
    def increment_processed(self):
        """å¢åŠ å¤„ç†è®¡æ•°"""
        with self.stats_lock:
            self.stats['processed'] += 1
        
    def increment_success(self):
        """å¢åŠ æˆåŠŸè®¡æ•°"""
        with self.stats_lock:
            self.stats['success'] += 1
        
    def increment_failure(self):
        """å¢åŠ å¤±è´¥è®¡æ•°"""
        with self.stats_lock:
            self.stats['failed'] += 1
        
    def emit_stats(self):
        """å‘é€ç»Ÿè®¡ä¿¡æ¯æ›´æ–°ä¿¡å·"""
        with self.stats_lock:
            self.stats_updated.emit(self.stats.copy())
    
    def calculate_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
        try:
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            self.log_message.emit(f"âŒ è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥: {file_path} - {str(e)}")
            return None
    
    def load_processed_files(self):
        """ä»æ–‡ä»¶åŠ è½½å·²å¤„ç†æ–‡ä»¶è®°å½•"""
        try:
            if os.path.exists(self.log_file_path):
                with open(self.log_file_path, 'r', encoding='utf-8') as f:
                    self.processed_files = json.load(f)
                self.log_message.emit(f"ğŸ“– å·²åŠ è½½ {len(self.processed_files)} æ¡å¤„ç†è®°å½•")
            else:
                self.processed_files = {}
                self.log_message.emit("ğŸ“ åˆ›å»ºæ–°çš„å¤„ç†è®°å½•æ–‡ä»¶")
        except Exception as e:
            self.log_message.emit(f"âŒ åŠ è½½å¤„ç†è®°å½•å¤±è´¥: {str(e)}")
            self.processed_files = {}
    
    def save_processed_files(self):
        """ä¿å­˜å·²å¤„ç†æ–‡ä»¶è®°å½•åˆ°æ–‡ä»¶"""
        try:
            with self.processed_files_lock:
                with open(self.log_file_path, 'w', encoding='utf-8') as f:
                    json.dump(self.processed_files, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.log_message.emit(f"âŒ ä¿å­˜å¤„ç†è®°å½•å¤±è´¥: {str(e)}")
    
    def is_file_processed(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»å¤„ç†è¿‡ï¼ˆåŸºäºå“ˆå¸Œå€¼ï¼‰"""
        try:
            if not os.path.exists(file_path):
                return True  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè®¤ä¸ºå·²å¤„ç†
            
            current_hash = self.calculate_file_hash(file_path)
            if not current_hash:
                return False  # æ— æ³•è®¡ç®—å“ˆå¸Œï¼Œéœ€è¦å¤„ç†
            
            with self.processed_files_lock:
                if file_path in self.processed_files:
                    stored_hash = self.processed_files[file_path].get('hash')
                    return stored_hash == current_hash
                return False  # æ–‡ä»¶æœªè®°å½•ï¼Œéœ€è¦å¤„ç†
        except Exception as e:
            self.log_message.emit(f"âŒ æ£€æŸ¥æ–‡ä»¶å¤„ç†çŠ¶æ€å¤±è´¥: {file_path} - {str(e)}")
            return False
    
    def mark_file_processed(self, file_path):
        """æ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†"""
        try:
            file_hash = self.calculate_file_hash(file_path)
            if file_hash:
                with self.processed_files_lock:
                    self.processed_files[file_path] = {
                        'hash': file_hash,
                        'timestamp': datetime.now().isoformat()
                    }
                self.save_processed_files()
        except Exception as e:
            self.log_message.emit(f"âŒ æ ‡è®°æ–‡ä»¶å¤„ç†çŠ¶æ€å¤±è´¥: {file_path} - {str(e)}")
    
    def is_image_file(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºæ”¯æŒçš„å›¾åƒæ ¼å¼"""
        if not Path(file_path).suffix.lower() in self.supported_formats:
            return False
            
        # è¿›ä¸€æ­¥æ£€æŸ¥æ–‡ä»¶åï¼Œæ’é™¤å¤‡ä»½æ–‡ä»¶
        filename = Path(file_path).name
        
        # æ’é™¤å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯å¤‡ä»½æ–‡ä»¶ï¼‰
        import re
        timestamp_pattern = r'_\d{8}_\d{6}'
        if re.search(timestamp_pattern, filename):
            return False
            
        # æ’é™¤å¤±è´¥æ ‡è®°çš„æ–‡ä»¶
        if '_FAILED_' in filename:
            return False
            
        return True
        
    def get_monitoring_status(self) -> dict:
        """è·å–ç›‘æ§çŠ¶æ€"""
        with self.stats_lock:
            return {
                'is_running': self.is_running,
                'monitored_folders': self.monitored_folders.copy(),
                'active_observers': len(self.observers),
                'processing_threads': len(self.processing_threads),
                'stats': self.stats.copy()
            }